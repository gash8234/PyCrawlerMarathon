{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加速：非同步爬蟲\n",
    "\n",
    "* 了解非同步爬蟲加速原理與實作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業目標\n",
    "\n",
    "* 比較一下非同步爬蟲跟多線程爬蟲的差異是什麼？各自的優缺點為何？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYour Input\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Your Input\n",
    "'''\n",
    "'''\n",
    "多線程爬蟲是藉由不同tread來同步執行爬蟲\n",
    "非同步爬蟲是藉由爬蟲排程將空白的地方(request花時間...)拿去做別的事情以減低整體時間，只會使用1個thread\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapy url :  https://www.dcard.tw/f/stock/p/236285134\n",
      "scrapy url :  https://www.dcard.tw/f/stock/p/236282709\n",
      "scrapy url :  https://www.dcard.tw/f/mood/p/236289487\n",
      "scrapy url :  https://www.dcard.tw/f/stock/p/236282709\n",
      "scrapy url :  https://www.dcard.tw/f/stock/p/236285134\n",
      "scrapy url :  https://www.dcard.tw/f/stock/p/236282709\n",
      "scrapy url :  https://www.dcard.tw/f/mood/p/236289487\n",
      "scrapy url :  https://www.dcard.tw/f/job/p/236292934\n",
      "花費:1.2720270156860352秒\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import _thread\n",
    "import time\n",
    "import re\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "T1=time.time()\n",
    "urls = ['https://www.dcard.tw/f/stock/p/236285134','https://www.dcard.tw/f/stock/p/236282709',\n",
    "       'https://www.dcard.tw/f/mood/p/236289487','https://www.dcard.tw/f/stock/p/236282709',\n",
    "       'https://www.dcard.tw/f/stock/p/236285134','https://www.dcard.tw/f/stock/p/236282709',\n",
    "       'https://www.dcard.tw/f/mood/p/236289487','https://www.dcard.tw/f/job/p/236292934']\n",
    "\n",
    "def normal_scrapy(url) :\n",
    "    r = requests.get(url)\n",
    "    r.encoding = 'utf-8'\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    reply = soup.find_all('section')[1].find('div',attrs={'style':re.compile('padding-top')})\n",
    "\n",
    "    comment=[]\n",
    "    #print(reply.find('div'))\n",
    "    for d in reply.find_all('div',attrs={'data-index':re.compile('[0-9]')}):\n",
    "        try :\n",
    "            floor = d.find('a' , attrs={'class':'sc-7fxob4-6 neiWc'}).text.replace(' ','')\n",
    "        except :\n",
    "            continue\n",
    "        com=[]\n",
    "        for c in d.find('div',attrs={'class':'phqjxq-0 fQNVmg'}).find_all('span') :\n",
    "            if c.string != None :\n",
    "                com.append(c.string)\n",
    "        if com !=[]:\n",
    "            comment.append(floor+':'+com[0])\n",
    "    \n",
    "    #for coment in comment : print(coment,'\\n\\n')\n",
    "    print('scrapy url : ', url  )\n",
    "#print(soup)\n",
    "for url in urls :\n",
    "    normal_scrapy(url)\n",
    "\n",
    "print(\"花費:\" + str(time.time() - T1) + \"秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapy url :  scrapy url : https://www.dcard.tw/f/stock/p/236285134\n",
      " https://www.dcard.tw/f/stock/p/236282709\n",
      "scrapy url :  https://www.dcard.tw/f/stock/p/236282709\n",
      "scrapy url :  https://www.dcard.tw/f/stock/p/236285134\n",
      "scrapy url :  https://www.dcard.tw/f/mood/p/236289487\n",
      "scrapy url :  https://www.dcard.tw/f/stock/p/236282709\n",
      "scrapy url :  https://www.dcard.tw/f/mood/p/236289487\n",
      "scrapy url :  https://www.dcard.tw/f/job/p/236292934\n",
      "花費:1.0234124660491943秒\n"
     ]
    }
   ],
   "source": [
    "\n",
    "T1=time.time()\n",
    "urls = ['https://www.dcard.tw/f/stock/p/236285134','https://www.dcard.tw/f/stock/p/236282709',\n",
    "       'https://www.dcard.tw/f/mood/p/236289487','https://www.dcard.tw/f/stock/p/236282709',\n",
    "       'https://www.dcard.tw/f/stock/p/236285134','https://www.dcard.tw/f/stock/p/236282709',\n",
    "       'https://www.dcard.tw/f/mood/p/236289487','https://www.dcard.tw/f/job/p/236292934']\n",
    "\n",
    "def dcard_scrapy (thread_name , url):\n",
    "    r = requests.get(url)\n",
    "    r.encoding = 'utf-8'\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    reply = soup.find_all('section')[1].find('div',attrs={'style':re.compile('padding-top')})\n",
    "\n",
    "    #print(reply.find('div'))\n",
    "    for d in reply.find_all('div',attrs={'data-index':re.compile('[0-9]')}):\n",
    "        comment=[]\n",
    "        try :\n",
    "            floor = d.find('a' , attrs={'class':'sc-7fxob4-6 neiWc'}).text.replace(' ','')\n",
    "        except :\n",
    "            continue\n",
    "        for c in d.find('div',attrs={'class':'phqjxq-0 fQNVmg'}).find_all('span') :\n",
    "            if c.string != None :\n",
    "                comment.append(c.string)\n",
    "        #print(thread_name,'-->',floor,':\\n',comment[0].replace(' ',''),\"\\n\")\n",
    "    print('scrapy url : ' ,url)\n",
    "    if(url == 'https://www.dcard.tw/f/job/p/236292934'):\n",
    "        print(\"花費:\" + str(time.time() - T1) + \"秒\")\n",
    "        \n",
    "\n",
    "i=1\n",
    "for url in urls:\n",
    "    _thread.start_new_thread(dcard_scrapy,('thread '+str(i),url))\n",
    "    i=i+1\n",
    "\n",
    "time.sleep(2)\n",
    "#print(\"花費:\" + str(T2 - T1) + \"秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapy url :  https://www.dcard.tw/f/job/p/236292934\n",
      "scrapy url :  https://www.dcard.tw/f/job/p/236292934\n",
      "scrapy url :  https://www.dcard.tw/f/job/p/236292934\n",
      "scrapy url :  https://www.dcard.tw/f/job/p/236292934\n",
      "scrapy url :  https://www.dcard.tw/f/job/p/236292934\n",
      "scrapy url :  https://www.dcard.tw/f/job/p/236292934\n",
      "scrapy url :  https://www.dcard.tw/f/job/p/236292934\n",
      "scrapy url :  https://www.dcard.tw/f/job/p/236292934\n",
      "花費:0.849513053894043秒\n"
     ]
    }
   ],
   "source": [
    "from aiohttp import ClientSession\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "T1=time.time()\n",
    "urls = ['https://www.dcard.tw/f/stock/p/236285134','https://www.dcard.tw/f/stock/p/236282709',\n",
    "       'https://www.dcard.tw/f/mood/p/236289487','https://www.dcard.tw/f/stock/p/236282709',\n",
    "       'https://www.dcard.tw/f/stock/p/236285134','https://www.dcard.tw/f/stock/p/236282709',\n",
    "       'https://www.dcard.tw/f/mood/p/236289487','https://www.dcard.tw/f/job/p/236292934']\n",
    "\n",
    "async def fetch(link,session):\n",
    "    async with session.get(link) as response:\n",
    "        r = await response.text()\n",
    "    \n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "    reply = soup.find_all('section')[1].find('div',attrs={'style':re.compile('padding-top')})\n",
    "\n",
    "    #print(reply.find('div'))\n",
    "    for d in reply.find_all('div',attrs={'data-index':re.compile('[0-9]')}):\n",
    "        comment=[]\n",
    "        try :\n",
    "            floor = d.find('a' , attrs={'class':'sc-7fxob4-6 neiWc'}).text.replace(' ','')\n",
    "        except :\n",
    "            continue\n",
    "        for c in d.find('div',attrs={'class':'phqjxq-0 fQNVmg'}).find_all('span') :\n",
    "            if c.string != None :\n",
    "                comment.append(c.string)\n",
    "        #print(thread_name,'-->',floor,':\\n',comment[0].replace(' ',''),\"\\n\")\n",
    "    print('scrapy url : ' ,url)\n",
    "    \n",
    "async def main(loop):\n",
    "    async with ClientSession() as session:\n",
    "        tasks = [loop.create_task(fetch(url, session)) for url in urls]\n",
    "        await asyncio.gather(*tasks)\n",
    "        \n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(main(loop))\n",
    "#loop.close()\n",
    "print(\"花費:\" + str(time.time() - T1) + \"秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
